# PROG ZBW_HDBSQL_CSV - Генерация скриптов для выгрузки данных BW в csv через hdbsql

## Описание бизнес-процесса системы
### Цель документа
Спецификация является основой для разработок, которые будут сделаны в SAP и не SAP системах. Заказчик должен проверить и утвердить её официально.
Реализация спецификации начнется только после утверждения со стороны заказчика.
### Описание бизнес-процесса
Разработка необходима для автоматизации процесса подготовки скриптов, которые вызывают hdbsql для генерации csv-файлов с данными. Файлы
предназначены для передачи в Hadoop.
### Предыстория
Текущий подход в выгрузки данных из BWP-HANA в Hadoop предполагает обращение со стороны Hadoop к HANA EE, которая через SDA обращается к HANA
BWP и передает в Hadoop результаты выполнения SELECT-операторов. Для повышения производительности передачи иногда выполняют распараллеливание
SELECT-запросов: каждый запрос возвращает свой определенный диапазон данных. Неоднократно замечена высокая нагрузка на сервер HANA-BWP при
одновременном выполнении большого числа обращений со стороны HANA EE (и, в свою очередь, из Hadoop). Иногда Hadoop вызывал загрузку данных из
BWP, когда данные еще не были полностью рассчитаны. Это приводило к необходимости повторных выгрузок.
Для устранения недостатков текущего подхода был разработан и реализован новый подход: выгрузка csv-файлов данных из HANA BWP посредством утилиты
hdbsql (стандартная утилита SAP HANA).
#### Достоинства нового подхода:
* более высокая производительность,
* упрощение ландшафта (HANA EE не требуется для этой задачи)
* бОльшая гибкость настройки правил формирования данных для выгрузки (SELECT-операторы)
* поддержка полной и дельта-выгрузки в csv
* управление регламентом выгрузки как со стороны источника данных (SAP BW), так и со стороны потребителя (Hadoop data engineers)
* ведения каталога выгрузок с указанием дельта-меток
* лицензионное соответствие SAP
#### Недостатки
* необходим контроль занимаемого csv-файлами дискового пространства на files share
* большее кол-во шагов для настройки регулярной выгрузки

## Архитектура нового подхода "выгрузка hdbsql через csv"
В результате выполнения процессов выгрузки, на fileshare создается zip-файл, который содержит 2 файла
* csv-файл (разделитель полей - запятая, кодировка - UTF8) с данными; csv-файл генерируется SAP-утилитой hdbsql
* def-файл (имена полей и типов данных полей в csv); генерируется ABAP-программой ZBW_HDBSQL_CSV
Стандартная SAP HANA-утилита hdbsql запускается на стороне сервера приложений BW. "На вход" hdbsql подаются параметры командной строки и файл c
SELECT-выражением для выгрузки. В результате, hdbsql подключается к HANA BWP под пользователем BWREAD. (у пользователя BWREAD установлена Locale =
'ru' на уровне учетной записи). Параметры подключения сохранены на сервере приложений, в User Secure Store. После окончания выполнения hdbsql
генерирует csv-файл в кодировке UTF-8. Поскольку размеры файлов могут доходить до сотни гигабайт, для оптимизации их копирования на hdfs
предусмотрено их zip-архивирование с последующим (опциональным) удалением оригиналов.
Вся последовательность действий: вызов hdbsql, архивация zip, удаление csv выполняется из sh-скрипта, который генерируется данной ABAP-программой и
сохраняется в определенном каталоге на сервере приложений BW (операционная система AIX). Той же программой генерируется sql-файл с командой(ами)
SELECT для выгрузки. Ошибки выполнения hdbsql журналируется в errorlog_x.txt (x от 1 до 9), который перезатирается при каждом запуске и сохраняется в том
же каталоге, что и sh-скрипт. В случае отсутствия ошибок файл errorlog_ч.txt должен быть пустым. Иначе, текст каждой ошибки содержит ":". Именно этот
символ проверяется на последнем шаге в цепочке процессов (см ниже). Если такой символ в errorlog_x.txt есть, то шаг цепочки получит красный статус.
Команда SELECT генерируется в методе ABAP-класса. Важно: на каждую структуру данных выгрузки, а, точнее, на каждый {параллельный ] поток необходимо
создавать отдельный класс, наследуя его от ZCL_BW_HDBSQLCSV_BASE. В классе-потомке надо переопределить
* конструктор (обязательное требование для всех потомков)
* метод SET_SELECT_SCRIPT
* метод SET_SELECT_SCRIPT_TT
* метод GET_DELTA_TEXT
* (опционально) метод BEFORE_RUN_HDBSQL
* (опционально) метод UPDATE_MISSED
См. примеры классов ZCL_BW_HDBSQLCSV_G0004S001 или ZCL_BW_HDBSQLCSV_G0002S001.
Класс с переопределенным методом BEFORE_RUN_HDBSQL - ZCL_BW_HDBSQLCSV_G0009S001.
Для запуска sh-скрипта используется цепочка процессов. Для каждой структуры данных выгрузки необходимо создать отдельную цепочку процессов, в
которой для каждого потока данных этой структуры последовательно вызываются следующие варианты процессов (в скобках - рекомендуемое техническое
имя шага, чтобы не запутаться при росте числа разных структур выгрузки, XXXX, XXX - номера групп и наборов соответственно):
1. ABAP-program: вызов ZBW_HDBSQL_CSV для формирования sh- и sql- файлов на сервере приложений BW. (ZGSXXXXSETXXX_MAKE) и def-файла
2. OS-command: вызов sh-файла. Если нет ошибок, то будет сформирован csv-файл данной структуры и для данного потока (ZGSXXXXSETXXX_SHHDBSQL)
3. (опционально) OS-command: анализ журнала выполнения. Если в журнале (errorlog_x.txt, x - от 1 до 9) встречается символ :, значит есть ошибка и
статус выполнения цепочки будет красным (ZGSXXXXSETXXX_CAT)
Пример цепочки - ZPC_GS002S002. Она настроена для одного потока одной структуры. В случае нескольких потоков одной структуры необходимо делать
отдельную цепочку для каждого потока или добавлять параллельные ветки в общую.

## Если надо ускорить выгрузку в csv
Можно применить распараллеливание внутри одного класса. Порядок настройки удобно иллюстрировать примером ZCL_BW_HDBSQLCSV_G0002S001
1. в таблице ZHDBSQLGS для G = g0002 и S = s001 определить несколько ( не более 10, номера POS от 0 до 9 включительно) позиций. В поле DELTA
указать критерий, который можно будет использовать в методе make_select_script для формирования текста SQL-запроса. И который (критерий)
позволит сконструировать запрос, который будет вызываться параллельно с другими запросами (не более 10).
2. В методе set_select_script получить DELTA из п.1 методом me->get_delta( ) и использовать полученное значение по усмотрению. В данном классе из
поля DELTA получают смещение в днях от текущей даты. Таким образом, в одном классе генерируется выполнение 10 параллельных SQL-SELECTзапросов, i от 0 до 9, каждый из которых собирает данные за интервал [ текущая дата "минус" d "минус" 2, текущая дата "минус" d ], а значения d = i i i
{1;4;7;10;13;16;...}

Важно обратить внимание, что если в настроечной таблице ZHDBSQLGS кол-во записей для одной G и S более 1, то sh-скрипт генерируется так, чтобы запускать
несколько параллельных запросов на выполнение. Это делается добавлением & в конце вызова команды. См. метод MAKE_PRIMARY_SCRIPT, счетчик lv_count.
Если в данных критерий распараллеливания трудно найти, можно использовать первую букву в текстовом поле и "нарезать" по этому критерию на болееменее одинаковые по мощности множества для выгрузок. В "нарезке" для MCLIENT поможет такой запрос
MCLIENT, определение примерно равномощных множеств
```sql
SELECT substr(name2,1,1) as letter1, count(*) as cnt FROM "SAPBWP"."/BIC/PCLIENT"
 GROUP BY substr(name2,1,1) ORDER BY 2 DESC;
SELECT * FROM "SAPBWP"."/BIC/MCLIENT"
 WHERE substr(name2,1,1) IN ('','','');
```

## Генерация def-файла
Файл помогает при настройки импорта данных в hadoop. Механизм генерации:
специальный SQL-SELECT запрос (определяется методом SET_SELECT_SCRIPT_TT) используется при создании локальной временной таблицы (ЛВТ). Когда ЛВТ
создается, то можно из HANA-словаря считать описание полей и их типов и сохранить описание в def-файле. По окончанию считывания ЛВТ автоматически
удаляется. Также, временная таблица удаляется автоматически при отключении пользователя от HANA. Важно, чтобы текст SQL-SELECT-запроса для данной
задачи был таким, чтобы
* содержал идентичные поля (названия, типы) и в идентичном порядке, как и в основном SQL-SELECT, который возвращает данные для csv-файла
* не содержал много строк
* корректность типов (особенно, длин строк) можно гарантировать использованием в SQL-SELECT функций типа substring
## Структура каталогов для хранения файлов и правила наименования
File-share в Tcode:AL11 - DIR_HDBSQL. Корневой каталог для выгрузки - hdbsql. Имена и пути одинаковые на всех серверах (D/Q/P) ландшафта
Правила именования каталогов на файловой системе сервера приложений BW:
* Каждой структуре (или в терминах программы - группе (group)) соответствует отдельный каталог. Имя каталога - gXXXX, где XXXX - число. Каждая
группа должна содержать как минимум один поток (см ниже)
* Каждому потоку (в терминах программы - набору (set)) соответствует отдельный подкаталог в каталоге группы. Имя подкаталога - sXXX, где XXX -
число
* Внутри подкаталога с набором 2 подкаталога - arch (для хранения select-скриптов), zip (для хранения zip-архивов с csv-файлами).
* Файлы sh И csv сохраняются в корне sXXX.
* Для хранения каталогов с наборами, которые "устарели", но их по ряду причин надо сохранить, предназначен подкаталог arch каталога группы gXXXX.

Пример: sh-файл для группы 0001 потока 001 должен быть сохранен в /mnt/hdbsqlexp/hdbsql/g0001/s001
После создания системы каталогов для каждой новой группы/набора необходимо дать
* всем aix-пользователям сервера приложений и пользователю, под которым будет подключаться hadoop, право на запись в эти каталоги (chmod o+w
<dir>).

Если каталоги создавались под aix-пользователем bwadm (как это и должно быть, т.к. эта задача выполняется SAP Basis), то шаг с присвоениями полномочий
bwadm можно опустить.
## Настройка delta-выгрузки
При необходимости, можно настроить дельта-выгрузку, при которой sh-скрипт будет генерировать csv-файлы, содержащие записи с большим значением т.н.
дельта-метки, чем при последней выгрузке. Дельта-сценарий возможен, если в выгружаемых данных есть поле, которое можно использоваться для дельтаметки. Обычно, это метка времени создания/изменения записи, но могут быть и другие поля. Какими бы они ни были, WHERE-ограничение с использованием
дельта-метки должно быть сгенерировано, а само значение метки на момент выгрузки - сохранено, чтобы при последующем извлечении получать данные с
большим (чем сохранено) значением этой метки.
Для сохранения меток используется таблица ZHDBSQLGS, поле DELTA (Char(250)). В этом поле допускается хранить любую информацию, достаточную для
корректной генерации SELECT-выражения в методе SET_SELECT_SCRIPT.
В случае необходимости поддержки дельта-обновления метод SET_SELECT_SCRIPT имеет следующий алгоритм работы:
1) получение метки времени последнего извлечения (чтение из таблицы ZHDBSQLGS), метод GET_DELTA
2) генерация SELECT-скрипта с добавлением условия WHERE типа "delta_field" > считанная_на_шаге_1_дельта-метка
3) Получение последнего значения (на момент выполнения) дельта-метки
4) Сохранение полученного значения дельта-метки в ZHDBSQLGS (метод SET_DELTA)
